{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing data with the SChunk class\n",
    "\n",
    "Although the ``NDArray`` class is the most widely used container for data in Blosc2, it (and many other containers like `C2Array`, `ProxySource`, etc.) is built on top of the `SChunk` class. The machinery of ``SChunk`` (from \"super-chunk\") is what makes it possible to easily and quickly create, append, insert, update and delete data and metadata in a these containers which inherit from the super-chunk container. Hence, it is worthwhile to learn how to use it directly. See this quick overview of the `SChunk` class in the [Python-Blosc2 documentation](../overview.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:15.188862Z",
     "start_time": "2025-07-25T14:38:15.185618Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import blosc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new ``SChunk`` instance\n",
    "One can initialize an ``SChunk`` instance with default parameters. If no data is provided, the space assigned to the chunked data will also be empty (since once can always extend and resize a super-chunk, this is not a problem). However, let's specify the parameters so they are different to defaults: we'll set `chunksize` (the size of each chunk in bytes), the `cparams` (compression parameters), the `dparams` (decompression parameters) and pass a `Storage` instance, which is used to persist the data on-disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:15.210122Z",
     "start_time": "2025-07-25T14:38:15.199645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blosc2.schunk.SChunk at 0x7384047ebb60>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cparams = blosc2.CParams(\n",
    "    codec=blosc2.Codec.BLOSCLZ,\n",
    "    typesize=4,\n",
    "    nthreads=8,\n",
    ")\n",
    "\n",
    "dparams = blosc2.DParams(\n",
    "    nthreads=16,\n",
    ")\n",
    "\n",
    "storage = blosc2.Storage(\n",
    "    contiguous=True,\n",
    "    urlpath=\"myfile.b2frame\",\n",
    "    mode=\"w\",  # create a new file\n",
    ")\n",
    "\n",
    "schunk = blosc2.SChunk(chunksize=10_000_000, cparams=cparams, dparams=dparams, storage=storage)\n",
    "schunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Great! So you have created your first super-chunk, persistent on-disk, with the desired compression codec and chunksize. We can now fill it with data, read it, update it, insert new chunks, etc."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append and read data\n",
    "\n",
    "We are going to add some data.  First, let's create the dataset, composed of 100 chunks of 2.5 million 4-bit integers each (i.e. an uncompressed size of 10 MB, the `chunksize` we specified above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:17.393429Z",
     "start_time": "2025-07-25T14:38:15.221191Z"
    }
   },
   "outputs": [],
   "source": [
    "buffer = [i * np.arange(2_500_000, dtype=\"int32\") for i in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Now we update the super chunk with the data for each chunk - the super chunk automatically extends the container to accommodate the new data, as we can verify by checking the number of chunks in the super-chunk after each append operation:"
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:17.723408Z",
     "start_time": "2025-07-25T14:38:17.403199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "-rw-r--r-- 1 lshaw lshaw 82M Jul 25 16:38 myfile.b2frame\r\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    nchunks = schunk.append_data(buffer[i])\n",
    "    assert nchunks == (i + 1)\n",
    "!ls -lh myfile.b2frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, while we have added 100 chunks of 10 MB (uncompressed) each, the data size of the frame on-disk is quite a bit less.  This is how compression is helping you to use less resources.\n",
    "\n",
    "In order to read the chunks from the on-disk SChunk we need to initiliaize a buffer and then use the ``decompress_chunk`` method, which will decompress the data into the provided buffer. The first argument is the chunk number to decompress, and the second one is the destination buffer where the decompressed data will be stored. After the loop, ``dest`` should contain the final chunk we added, which was ``99 * np.arange(2_500_000, dtype=\"int32\")``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:17.945637Z",
     "start_time": "2025-07-25T14:38:17.742746Z"
    }
   },
   "outputs": [],
   "source": [
    "dest = np.empty(2_500_000, dtype=\"int32\")\n",
    "for i in range(100):\n",
    "    chunk = schunk.decompress_chunk(i, dest)\n",
    "## Final chunk should be equal to checker\n",
    "checker = 99 * np.arange(2_500_000, dtype=\"int32\")\n",
    "np.testing.assert_equal(dest, checker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating and inserting\n",
    "\n",
    "We can update the first chunk with some new. Unlike for the ``append`` operation, we must first compress the data into a blosc2-compatible form and then update the desired chunk in-place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:17.987630Z",
     "start_time": "2025-07-25T14:38:17.955796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_up = np.arange(2_500_000, dtype=\"int32\")\n",
    "chunk = blosc2.compress2(data_up)\n",
    "schunk.update_chunk(nchunk=0, chunk=chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The function then returns the number of chunks in the SChunk, which is the same as before, since we have overwritten the old chunk data at chunk position 0. On the other hand, if we insert a chunk at position 4 we increase the indices of the following chunks, so the number of chunks in the SChunk will increase by one:"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:18.004083Z",
     "start_time": "2025-07-25T14:38:17.997185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 506 μs, sys: 194 μs, total: 700 μs\n",
      "Wall time: 705 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "schunk.insert_chunk(nchunk=4, chunk=chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In this case the return value is the new number of chunks in the super-chunk. This is a rapid operation since the chunks are not stored contiguously and so incrementing their index is just a matter of updating the metadata, not moving any data around."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metalayers and variable length metalayers\n",
    "Upon creation of the SChunk, one may pass compression/decompression and storage parameters to the constructor as we have seen, which may be accessed (although not in general modified) as attributes of the instance. In addition, one may add *metalayers* which contain custom metadata summarising the container-stored data. There are two kinds of metalayers, both if which use a dictionary-like interface. The first one, ``meta``, must be added at construction time; it cannot be deleted and can only be updated with values that have the same bytes size as the old value. They are easy to access and edit by users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:18.018373Z",
     "start_time": "2025-07-25T14:38:18.014443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta keys: ['meta1']\n",
      "meta1 before modification: 234\n",
      "meta1 after modification: 235\n"
     ]
    }
   ],
   "source": [
    "schunk = blosc2.SChunk(meta={\"meta1\": 234})\n",
    "print(f\"Meta keys: {schunk.meta.keys()}\")\n",
    "print(f\"meta1 before modification: {schunk.meta['meta1']}\")\n",
    "schunk.meta[\"meta1\"] = 235\n",
    "print(f\"meta1 after modification: {schunk.meta['meta1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "A second type of metalayer, `vlmeta`, offers more flexibility. ``vlmeta`` stands for \"variable length metadata\", and, as the name suggests, is designed to store general, variable length data. You can add arbitrary entries to `vlmeta` after the creation of the SChunk, update entries with different bytes size values or indeed delete them. `vlmeta` follows the dictionary interface, and so one may add entries to it like this:"
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:18.044192Z",
     "start_time": "2025-07-25T14:38:18.036348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info1': 'This is an example', b'info2': 'of user meta handling'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schunk.vlmeta[\"info1\"] = \"This is an example\"\n",
    "schunk.vlmeta[\"info2\"] = \"of user meta handling\"\n",
    "schunk.vlmeta.getall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The entries may also be modified with larger values than the original ones:"
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:18.061659Z",
     "start_time": "2025-07-25T14:38:18.054708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info1': 'This is a larger example', b'info2': 'of user meta handling'}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schunk.vlmeta[\"info1\"] = \"This is a larger example\"\n",
    "schunk.vlmeta.getall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Finally, one may delete some of the entries:"
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:18.076977Z",
     "start_time": "2025-07-25T14:38:18.072149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info2': 'of user meta handling'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del schunk.vlmeta[\"info1\"]\n",
    "schunk.vlmeta.getall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using metalayers with NDArray\n",
    "Naturally, any object which inherits from ``SChunk`` also supports both flavours of metalayer. Consequently, one may add such metalayers to ``NDArray`` objects, which are the most commonly used containers in Blosc2. Hence we may add ``metaa`at construction time, in the following way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:18.091902Z",
     "start_time": "2025-07-25T14:38:18.087241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b2nd': [0, 2, [1000, 1000], [100, 100], [50, 50], 0, '<i2'], 'dtype': 'i8', 'coords': [5.14, 23.0]}\n",
      "['b2nd', 'dtype', 'coords']\n"
     ]
    }
   ],
   "source": [
    "meta = {\"dtype\": \"i8\", \"coords\": [5.14, 23.0]}\n",
    "array = blosc2.zeros((1000, 1000), dtype=np.int16, chunks=(100, 100), blocks=(50, 50), meta=meta)\n",
    "print(array.meta)\n",
    "print(array.meta.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "As you can see, Blosc2 internally a ``'b2nd'`` entry to ``meta`` (which by default is empty for a vanilla SChunk) to store shapes, ndim, dtype, etc, and retrieve this data when needed. We can hone in on our own user meta that we added like so:"
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:18.216043Z",
     "start_time": "2025-07-25T14:38:18.211309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.14, 23.0]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.meta[\"coords\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "If adding a metalayer after creation, one must use the ``vlmeta`` attribute of the underlying SChunk, which also works like a dictionary:"
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:18.246489Z",
     "start_time": "2025-07-25T14:38:18.237854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{b'info1': 'This is an example', b'info2': 'of user meta handling'}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(array.vlmeta[:])\n",
    "array.vlmeta[\"info1\"] = \"This is an example\"\n",
    "array.vlmeta[\"info2\"] = \"of user meta handling\"\n",
    "array.vlmeta[:]  # this return all the metadata as a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can update them with a value larger than the original one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:18.269843Z",
     "start_time": "2025-07-25T14:38:18.262175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info1': 'This is a larger example', b'info2': 'of user meta handling'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.vlmeta[\"info1\"] = \"This is a larger example\"\n",
    "array.vlmeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Indeed you can store any kind of data in the vlmeta metalayer, as long as it is serializable with msgpack. This is a very flexible way to store metadata in a Blosc2 container."
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:18.288947Z",
     "start_time": "2025-07-25T14:38:18.280224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info1': 'This is a larger example', b'info2': 'of user meta handling', b'info3': {'a': 1, 'b': 2}}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.vlmeta[\"info3\"] = {\"a\": 1, \"b\": 2}\n",
    "array.vlmeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Variable length metadata can be deleted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:38:18.313871Z",
     "start_time": "2025-07-25T14:38:18.306961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info2': 'of user meta handling', b'info3': {'a': 1, 'b': 2}}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del array.vlmeta[\"info1\"]\n",
    "array.vlmeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "This is very useful to store metadata that is not known at the time of creation of the container, or that can be updated or deleted at any time.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "That's all for now.  There are more examples in the [examples directory of the git repository](https://github.com/Blosc/python-blosc2/tree/main/examples) for you to explore.  Enjoy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
