{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing data with the SChunk class\n",
    "\n",
    "Although the ``NDArray`` class is the most widely used container for data in Blosc2, it (and many other containers like `C2Array`, `ProxySource`, etc.) is built on top of the `SChunk` class. The machinery of ``SChunk`` (from \"super-chunk\") is what makes it possible to easily and quickly create, append, insert, update and delete data and metadata for these containers which inherit from the super-chunk container. Hence, it is worthwhile to learn how to use ``SChunk`` directly. See this quick overview of the `SChunk` class in the [Python-Blosc2 documentation](../overview.html)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:27.372464Z",
     "start_time": "2025-08-05T08:16:27.016363Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "import blosc2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new ``SChunk`` instance\n",
    "One can initialize an ``SChunk`` instance with default parameters. If no data is provided, the space assigned to the chunked data will also be empty (since once can always extend and resize a super-chunk, this is not a problem). However, let's specify the parameters so they are different to defaults: we'll set `chunksize` (the size of each chunk in bytes), the `cparams` (compression parameters), the `dparams` (decompression parameters) and pass a `Storage` instance, which is used to persist the data on-disk."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:27.390406Z",
     "start_time": "2025-08-05T08:16:27.381588Z"
    }
   },
   "source": [
    "cparams = blosc2.CParams(\n",
    "    codec=blosc2.Codec.BLOSCLZ,\n",
    "    typesize=4,\n",
    "    nthreads=8,\n",
    ")\n",
    "\n",
    "dparams = blosc2.DParams(\n",
    "    nthreads=16,\n",
    ")\n",
    "\n",
    "storage = blosc2.Storage(\n",
    "    contiguous=True,\n",
    "    urlpath=\"myfile.b2frame\",\n",
    "    mode=\"w\",  # create a new file\n",
    ")\n",
    "\n",
    "schunk = blosc2.SChunk(chunksize=10_000_000, cparams=cparams, dparams=dparams, storage=storage)\n",
    "schunk"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blosc2.schunk.SChunk at 0x7821e04cfd90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Great! So you have created your first super-chunk, persistent on-disk, with the desired compression codec and chunksize. We can now fill it with data, read it, update it, insert new chunks, etc."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append and read data\n",
    "\n",
    "We are going to add some data.  First, let's create the dataset, composed of 100 chunks of 2.5 million 4-bit integers each. This means each chunk has an uncompressed size of 10 MB, the `chunksize` we specified above - this way we know for sure that the batches of data will fit into the predetermined chunks of the super-chunk (although after compression, we expect each chunk to end up being quite a bit smaller)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:28.310822Z",
     "start_time": "2025-08-05T08:16:27.575169Z"
    }
   },
   "source": [
    "buffer = [i * np.arange(2_500_000, dtype=\"int32\") for i in range(100)]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Now we update the super chunk with the data for each chunk - the super chunk automatically extends the container to accommodate the new data, as we can verify by checking the number of chunks in the super-chunk after each append operation:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:28.676151Z",
     "start_time": "2025-08-05T08:16:28.320882Z"
    }
   },
   "source": [
    "for i in range(100):\n",
    "    nchunks = schunk.append_data(buffer[i])\n",
    "    assert nchunks == (i + 1)\n",
    "!ls -lh myfile.b2frame"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "-rw-r--r-- 1 lshaw lshaw 82M Aug  5 10:16 myfile.b2frame\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, while we have added 100 chunks of 10 MB (uncompressed) each, the data size of the frame on-disk is quite a bit less.  This is how compression is helping you to use less resources.\n",
    "\n",
    "In order to read the chunks from the on-disk SChunk we need to initialize a buffer and then use the ``decompress_chunk`` method, which will decompress the data into the provided buffer. The first argument is the chunk number to decompress, and the second one is the destination buffer where the decompressed data will be stored. After the loop, ``dest`` should contain the final chunk we added, which was ``99 * np.arange(2_500_000, dtype=\"int32\")``:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:28.914236Z",
     "start_time": "2025-08-05T08:16:28.691526Z"
    }
   },
   "source": [
    "dest = np.empty(2_500_000, dtype=\"int32\")\n",
    "for i in range(100):\n",
    "    chunk = schunk.decompress_chunk(i, dest)\n",
    "## Final chunk should be equal to checker\n",
    "checker = 99 * np.arange(2_500_000, dtype=\"int32\")\n",
    "np.testing.assert_equal(dest, checker)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating and inserting\n",
    "\n",
    "We can update the first chunk with some new data. Unlike for the ``append`` operation, we must first compress the data into a Blosc2-compatible form and then update the desired chunk in-place:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:28.939744Z",
     "start_time": "2025-08-05T08:16:28.925561Z"
    }
   },
   "source": [
    "data_up = np.arange(2_500_000, dtype=\"int32\")\n",
    "chunk = blosc2.compress2(data_up)\n",
    "schunk.update_chunk(nchunk=0, chunk=chunk)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The function then returns the number of chunks in the SChunk, which is the same as before, since we have overwritten the old chunk data at chunk position 0. On the other hand, if we insert a chunk at position 4 we increase the indices of the following chunks, so the number of chunks in the SChunk will increase by one:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:28.955990Z",
     "start_time": "2025-08-05T08:16:28.949584Z"
    }
   },
   "source": [
    "%%time\n",
    "schunk.insert_chunk(nchunk=4, chunk=chunk)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 400 μs, sys: 204 μs, total: 604 μs\n",
      "Wall time: 526 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In this case the return value is the new number of chunks in the super-chunk. This is a rapid operation since the chunks are not stored contiguously and so incrementing their index is just a matter of updating the metadata, not moving any data around."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metalayers and variable length metalayers\n",
    "Upon creation of the SChunk, one may pass compression/decompression and storage parameters to the constructor as we have seen, which may be accessed (although not in general modified) as attributes of the instance. In addition, one may add *metalayers* which contain custom metadata summarising the container-stored data. There are two kinds of metalayers, both of which use a dictionary-like interface. The first one, ``meta``, must be added at construction time; it cannot be deleted and can only be updated with values that have the same bytes size as the old value. They are easy to access and edit by users:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:28.983612Z",
     "start_time": "2025-08-05T08:16:28.976972Z"
    }
   },
   "source": [
    "schunk = blosc2.SChunk(meta={\"meta1\": 234})\n",
    "print(f\"Meta keys: {schunk.meta.keys()}\")\n",
    "print(f\"meta1 before modification: {schunk.meta['meta1']}\")\n",
    "schunk.meta[\"meta1\"] = 235\n",
    "print(f\"meta1 after modification: {schunk.meta['meta1']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta keys: ['meta1']\n",
      "meta1 before modification: 234\n",
      "meta1 after modification: 235\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "A second type of metalayer, `vlmeta`, offers more flexibility. ``vlmeta`` stands for \"variable length metadata\", and, as the name suggests, is designed to store general, variable length data. You can add arbitrary entries to `vlmeta` after the creation of the SChunk, update entries with different bytes size values or indeed delete them. `vlmeta` follows the dictionary interface, and so one may add entries to it like this:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:29.010755Z",
     "start_time": "2025-08-05T08:16:29.002070Z"
    }
   },
   "source": [
    "schunk.vlmeta[\"info1\"] = \"This is an example\"\n",
    "schunk.vlmeta[\"info2\"] = \"of user meta handling\"\n",
    "schunk.vlmeta.getall()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info1': 'This is an example', b'info2': 'of user meta handling'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The entries may also be modified with larger values than the original ones:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:29.039851Z",
     "start_time": "2025-08-05T08:16:29.032948Z"
    }
   },
   "source": [
    "schunk.vlmeta[\"info1\"] = \"This is a larger example\"\n",
    "schunk.vlmeta.getall()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info1': 'This is a larger example', b'info2': 'of user meta handling'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Finally, one may delete some of the entries:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:29.060249Z",
     "start_time": "2025-08-05T08:16:29.053758Z"
    }
   },
   "source": [
    "del schunk.vlmeta[\"info1\"]\n",
    "schunk.vlmeta.getall()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info2': 'of user meta handling'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using metalayers with NDArray\n",
    "Naturally, any object which inherits from ``SChunk`` also supports both flavours of metalayer. Consequently, one may add such metalayers to ``NDArray`` objects, which are the most commonly used containers in Blosc2. Hence we may add ``meta`` at construction time, in the following way"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:29.075142Z",
     "start_time": "2025-08-05T08:16:29.070019Z"
    }
   },
   "source": [
    "meta = {\"dtype\": \"i8\", \"coords\": [5.14, 23.0]}\n",
    "array = blosc2.zeros((1000, 1000), dtype=np.int16, chunks=(100, 100), blocks=(50, 50), meta=meta)\n",
    "print(array.meta)\n",
    "print(array.meta.keys())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b2nd': [0, 2, [1000, 1000], [100, 100], [50, 50], 0, '<i2'], 'dtype': 'i8', 'coords': [5.14, 23.0]}\n",
      "['b2nd', 'dtype', 'coords']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "As you can see, Blosc2 internally adds a ``'b2nd'`` entry to ``meta`` when dealing with an NDArray (which by default is empty for a vanilla SChunk) to store shapes, ndim, dtype, etc, and retrieve this data when needed. We can hone in on our own user ``meta`` that we added like so:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:29.096970Z",
     "start_time": "2025-08-05T08:16:29.092695Z"
    }
   },
   "source": [
    "array.meta[\"coords\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.14, 23.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "If adding a metalayer after creation, one must use the ``vlmeta`` attribute of the underlying SChunk, which also works like a dictionary:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:29.125454Z",
     "start_time": "2025-08-05T08:16:29.115921Z"
    }
   },
   "source": [
    "print(array.vlmeta[:])\n",
    "array.vlmeta[\"info1\"] = \"This is an example\"\n",
    "array.vlmeta[\"info2\"] = \"of user meta handling\"\n",
    "array.vlmeta[:]  # this return all the metadata as a dictionary"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{b'info1': 'This is an example', b'info2': 'of user meta handling'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As before, we can update the ``vlmeta`` with a value larger than the original one:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:29.151892Z",
     "start_time": "2025-08-05T08:16:29.145451Z"
    }
   },
   "source": [
    "array.vlmeta[\"info1\"] = \"This is a larger example\"\n",
    "array.vlmeta"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info1': 'This is a larger example', b'info2': 'of user meta handling'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Indeed you can store any kind of data in the ``vlmeta`` metalayer, as long as it is serializable with ``msgpack``. This is a very flexible way to store metadata in a Blosc2 container."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:29.177432Z",
     "start_time": "2025-08-05T08:16:29.169652Z"
    }
   },
   "source": [
    "array.vlmeta[\"info3\"] = {\"a\": 1, \"b\": 2}\n",
    "array.vlmeta"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info1': 'This is a larger example', b'info2': 'of user meta handling', b'info3': {'a': 1, 'b': 2}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Variable length metadata can be deleted:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:16:29.289617Z",
     "start_time": "2025-08-05T08:16:29.276356Z"
    }
   },
   "source": [
    "del array.vlmeta[\"info1\"]\n",
    "array.vlmeta"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'info2': 'of user meta handling', b'info3': {'a': 1, 'b': 2}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "This is very useful to store metadata that is not known at the time of creation of the container, or that can be updated or deleted at any time.\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T08:17:08.151380Z",
     "start_time": "2025-08-05T08:17:08.137716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# clean up\n",
    "blosc2.remove_urlpath(\"myfile.b2frame\")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "That's all for now.  There are more examples in the [examples directory of the git repository](https://github.com/Blosc/python-blosc2/tree/main/examples) for you to explore (see ``blosc2_hdf5_compression.py``, ``schunk.py`` and ``schunk_roundtrip.py`` for some examples of SChunk usage).  Enjoy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
