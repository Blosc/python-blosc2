{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-defined codecs and filters\n",
    "While Python-Blosc2 offers many standard [codecs](../../reference/autofiles/low_level/blosc2.Codec.html) and [filters](../../reference/autofiles/low_level/blosc2.Filter.html) to enable custom compression, one may wish to use user-defined compression algorithms. This is possible in Python-Blosc2 via Python functions which may act as user-defined codecs and filters. These will work as normal codecs or filters respectively following the order depicted below:\n",
    "\n",
    "<div style=\"background-color: white;\">\n",
    "<img src=\"images/blosc2-pipeline.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "So when compressing, the first step will be to apply the prefilter (if any), then the filter pipeline with a maximum of six filters and, last but not least, the codec. For decompressing, the order will be the other way around: first the codec, then the filter pipeline and finally the postfilter (if any).\n",
    "\n",
    "In this tutorial we will see how to create and use custom codecs and filters (see the next tutorial for post-/prefilters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined codecs\n",
    "\n",
    "Predefined codecs in Blosc2 use low-level C functions and so are amenable to parallelisation. Because a user-defined codec has Python code, we will not be able to use parallelism, so `nthreads` has to be 1 when compressing and decompressing. We set `nthreads=1` in the `CParams` and `DParams` objects that we will use to create the `SChunk` instance. When using user-defined codes, we may also specify ``codec_meta`` in the ``CParams`` instance as an integer between 0 and 255 (see ``compcode_meta`` [here](https://github.com/Blosc/c-blosc2/blob/main/README_CFRAME_FORMAT.rst)). This meta will be passed to the codec's *encoder* and *decoder* functions, where it can be interpreted as one desires. We may also pass ``filters_meta`` in the `CParams` object, which will be passed to the user-defined filters *forward* and *backward* functions. Later on, we will update the `CParams` object with our user-defined codec and filters, and update the meta at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:34.957869Z",
     "start_time": "2025-08-05T16:08:34.689868Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import blosc2\n",
    "\n",
    "dtype = np.dtype(np.int32)\n",
    "cparams = blosc2.CParams(nthreads=1, typesize=dtype.itemsize)\n",
    "dparams = blosc2.DParams(nthreads=1)\n",
    "\n",
    "chunk_len = 1000\n",
    "schunk = blosc2.SChunk(chunksize=chunk_len * dtype.itemsize, cparams=cparams, dparams=dparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Creating a codec\n",
    "\n",
    "To create a codec we need two functions: one for compressing (aka *encoder*) and another for decompressing (aka *decoder*). In order to explain the procedure, we will create a codec for repeated values. First we programme the *encoder* function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:34.970310Z",
     "start_time": "2025-08-05T16:08:34.965888Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def encoder(input, output, meta, schunk):\n",
    "    nd_input = input.view(dtype)\n",
    "    # Check if all the values are the same\n",
    "    if np.max(nd_input) == np.min(nd_input):\n",
    "        # output = [value, nrep]\n",
    "        output[0 : schunk.typesize] = input[0 : schunk.typesize]\n",
    "        byteorder = \"little\" if meta == 0 else \"big\"\n",
    "        n = nd_input.size.to_bytes(4, byteorder)\n",
    "        output[schunk.typesize : schunk.typesize + 4] = [n[i] for i in range(4)]\n",
    "        return schunk.typesize + 4\n",
    "    else:\n",
    "        # memcpy\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be compatible with the Blosc2 internal compression machinery, which operates blockwise, the encoder function requires 4 arguments: the input data block; the output buffer into which the data is compressed; the codec meta (which here we decide will be used to indicate the [\"endianness\"](https://en.wikipedia.org/wiki/Endianness) of the bytes); and the `SChunk` instance which hosts the compressed block. The *encoder* must then return the size of the compressed buffer in bytes. If it cannot compress the data, it must return 0 - Blosc2 will then know to simply copy the block without compressing. The image below depicts what our *encoder* does:\n",
    "\n",
    "<div style=\"background-color: white;\">\n",
    "<img src=\"images/ucodecs-filters/encoder.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Now let's go for the *decoder*, which also expects to receive the same 4 arguments, and operates blockwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.038321Z",
     "start_time": "2025-08-05T16:08:35.033897Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decoder(input, output, meta, schunk):\n",
    "    byteorder = \"little\" if meta == 0 else \"big\"\n",
    "    if byteorder == \"little\":\n",
    "        nd_input = input.view(\"<i4\")\n",
    "    else:\n",
    "        nd_input = input.view(\">i4\")\n",
    "    nd_output = output.view(\"i4\")\n",
    "    nd_output[0 : nd_input[1]] = [nd_input[0]] * nd_input[1]\n",
    "    return nd_input[1] * schunk.typesize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *decoder* function must return the size of the decompressed buffer in bytes; it receives the output filled by the encoder as the input param, and will recreate the data again following this scheme:\n",
    "\n",
    "<div style=\"background-color: white;\">\n",
    "<img src=\"images/ucodecs-filters/decoder.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Note that if a block was memcopied (uncompressed) by Blosc2 the *decoder* will be skipped when requesting data from the SChunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Registering and Using a codec\n",
    "\n",
    "Once the codec's procedures are defined, we can register it to the local Blosc2 codec registry! For that, we must choose an identifier between 160 and 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.050108Z",
     "start_time": "2025-08-05T16:08:35.047278Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "codec_name = \"our_codec\"\n",
    "codec_id = 160\n",
    "blosc2.register_codec(codec_name, codec_id, encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": "The codec can now be specified in the compression params of an SChunk instance using its id. We also pass the ``codec_meta`` that we want our codec to use in the encoder and decoder. Since we designed the codec to receive the original data with no changes, we specify that no filters are to be used:"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.066023Z",
     "start_time": "2025-08-05T16:08:35.059165Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CParams(codec=160, codec_meta=0, clevel=1, use_dict=False, typesize=4, nthreads=1, blocksize=0, splitmode=<SplitMode.AUTO_SPLIT: 3>, filters=[<Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>], filters_meta=[0, 0, 0, 0, 0, 0], tuner=<Tuner.STUNE: 0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codec_meta = 0 if sys.byteorder == \"little\" else 1\n",
    "for k, v in {\n",
    "    \"codec\": codec_id,\n",
    "    \"codec_meta\": codec_meta,\n",
    "    \"filters\": [blosc2.Filter.NOFILTER],\n",
    "    \"filters_meta\": [0],\n",
    "}.items():\n",
    "    setattr(cparams, k, v)\n",
    "schunk.cparams = cparams\n",
    "schunk.cparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": "Note that it is important to update the whole ``cparams`` attribute at the same time, and not the individual attributes e.g. ``cparams.codec``, since the latter do not have setters defined (whereas ``SChunk`` does have a ``cparams`` setter defined), and so will not update the compression parameters correctly; i.e. ``schunk.cparams.codec = 160`` will not correctly update the internal C machinery. Now we can check that our codec works well by appending and recovering some data, composed of three chunks, each of which is made of a different repeated value - the compression goes blockwise, so many blocks will be composed of a single repeated value and will be compressed by the codec."
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.092728Z",
     "start_time": "2025-08-05T16:08:35.084110Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schunk cratio:  83.33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_value = 1234\n",
    "a = np.full(chunk_len, fill_value, dtype=dtype)\n",
    "b = np.full(chunk_len, fill_value + 1, dtype=dtype)\n",
    "c = np.full(chunk_len, fill_value + 2, dtype=dtype)\n",
    "data = np.concat((a, b, c))\n",
    "schunk[0 : data.size] = data\n",
    "print(\"schunk cratio: \", round(schunk.cratio, 2))\n",
    "\n",
    "out = np.empty(data.shape, dtype=dtype)\n",
    "schunk.get_slice(out=out)\n",
    "\n",
    "np.array_equal(data, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Awesome, it works! However, if the array is not composed of blocks with repeated values our codec will not compress anything. In the next section, we will create and use a filter and perform a little modification to our codec so that we can compress even if the data is made out of equally spaced values.\n",
    "\n",
    "## User-defined filters\n",
    "\n",
    "Writing and registering filters is not too different to writing and registering codecs. Filters do not directly compress data, but rather manipulate it to make it easier to compress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Creating a filter\n",
    "\n",
    "As for user-defined codecs, to create a user-defined filter we will first need to create two functions: one for the compression process (aka *forward*) and another one for the decompression process (aka *backward*).\n",
    "\n",
    "Let's write first the *forward* function. Its signature is exactly the same as the *encoder*/*decoder* signature, although here the meta will be passed from the ``filters_meta`` attribute of the ``CParams`` instance associated to ``schunk`` (which does not necessarily have to be used). Neither the *forward* nor *backward* functions have to return anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.115900Z",
     "start_time": "2025-08-05T16:08:35.111892Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def forward(input, output, meta, schunk):\n",
    "    nd_input = input.view(dtype)\n",
    "    nd_output = output.view(dtype)\n",
    "\n",
    "    start = nd_input[0]\n",
    "    nd_output[0] = start\n",
    "    nd_output[1:] = nd_input[1:] - nd_input[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our *forward* function keeps the start value, and then it computes the difference between each element and the one next to it just like the following image shows. As a consequence, after passing through the filter, equally spaced data will be processed into an array with many repeated values. Later on, we will write a new codec which will be able to compress/decompress this filtered data.\n",
    "\n",
    "\n",
    "<div style=\"background-color: white;\">\n",
    "<img src=\"images/ucodecs-filters/forward.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "The *backward* function applies the inverse transform to the *forward* function, so it will reconstruct the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.138093Z",
     "start_time": "2025-08-05T16:08:35.134900Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def backward(input, output, meta, schunk):\n",
    "    nd_input = input.view(dtype)\n",
    "    nd_output = output.view(dtype)\n",
    "\n",
    "    nd_output[0] = nd_input[0]\n",
    "    for i in range(1, nd_output.size):\n",
    "        nd_output[i] = nd_output[i - 1] + nd_input[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hence when called on the output of the *forward* function, it will reconstruct the original data as follows:\n",
    "<div style=\"background-color: white;\">\n",
    "<img src=\"images/ucodecs-filters/backward.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "### Registering and Using a filter\n",
    "\n",
    "Once we have the two required functions, we can register our filter. In the same way we did for the codecs, we have to choose an identifier between 160 and 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.148096Z",
     "start_time": "2025-08-05T16:08:35.144684Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filter_id = 160\n",
    "blosc2.register_filter(filter_id, forward, backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": "The filter can now be introduced into the SChunk's filter pipeline via updating the `cparams` attribute of the `SChunk` instance with a list of the filters to be applied, indicated by their unique id (in this case just the filter we created), and their corresponding `filters_meta` (in this case it is unimportant, as the filter does not use it). We also need to update the codec used so that we can take advantage of the filter first though."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Writing a new codec for the filtered data\n",
    "Next, we are going to create another codec to compress data passed by the filter. This will get the start value and the step when compressing, and will rebuild the data from those values when decompressing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.162556Z",
     "start_time": "2025-08-05T16:08:35.157998Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def encoder2(input, output, meta, schunk):\n",
    "    nd_input = input.view(dtype)\n",
    "    if np.min(nd_input[1:]) == np.max(nd_input[1:]):\n",
    "        output[0 : schunk.typesize] = input[0 : schunk.typesize]  # start\n",
    "        step = int(nd_input[1])\n",
    "        n = step.to_bytes(4, sys.byteorder)\n",
    "        output[schunk.typesize : schunk.typesize + 4] = [n[i] for i in range(4)]\n",
    "        return schunk.typesize + 4\n",
    "    else:\n",
    "        # Not compressible, tell Blosc2 to do a memcpy\n",
    "        return 0\n",
    "\n",
    "\n",
    "def decoder2(input, output, meta, schunk):\n",
    "    nd_input = input.view(dtype)\n",
    "    nd_output = output.view(dtype)\n",
    "    nd_output[0] = nd_input[0]\n",
    "    nd_output[1:] = nd_input[1]\n",
    "\n",
    "    return nd_output.size * schunk.typesize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their corresponding schemes are as follows:\n",
    "\n",
    "<div style=\"background-color: white;\">\n",
    "<img src=\"images/ucodecs-filters/encoder2.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: white;\">\n",
    "<img src=\"images/ucodecs-filters/decoder2.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "As the previous id is already in use, we will register it with another identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.176293Z",
     "start_time": "2025-08-05T16:08:35.172678Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "blosc2.register_codec(codec_name=\"our_codec2\", id=184, encoder=encoder2, decoder=decoder2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Now we update the schunk's `cparams` to use the new codec as well as the filter we just registered. We will also set the `codec_meta` to 0, although it isn't used by our new codec."
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.192354Z",
     "start_time": "2025-08-05T16:08:35.186030Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CParams(codec=184, codec_meta=0, clevel=1, use_dict=False, typesize=4, nthreads=1, blocksize=0, splitmode=<SplitMode.AUTO_SPLIT: 3>, filters=[160, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>], filters_meta=[0, 0, 0, 0, 0, 0], tuner=<Tuner.STUNE: 0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cparams.filters = [filter_id]\n",
    "cparams.filters_meta = [0]\n",
    "cparams.codec = 184\n",
    "cparams.codec_meta = 0\n",
    "schunk.cparams = cparams\n",
    "schunk.cparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check that it actually works by updating the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.210993Z",
     "start_time": "2025-08-05T16:08:35.203331Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schunk compression ratio:  83.33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nchunks = 3\n",
    "new_data = np.arange(chunk_len, chunk_len * (nchunks + 1), dtype=dtype)\n",
    "\n",
    "schunk[0 : new_data.size] = new_data\n",
    "print(\"schunk compression ratio: \", round(schunk.cratio, 2))\n",
    "\n",
    "out = np.empty(new_data.shape, dtype=dtype)\n",
    "schunk.get_slice(out=out)\n",
    "np.array_equal(new_data, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As can be seen, we obtained the same compression ratio as before - since we store each of the 3 chunks using 8 bytes each.\n",
    "\n",
    "## Conclusion and NDArray arrays\n",
    "So now, whenever you need it, you can register a codec or filter and use it in your data! Note that one can also define and apply codecs and filters to `blosc2.NDArray` objects, since they are based on the `SChunk` class, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T16:08:35.235586Z",
     "start_time": "2025-08-05T16:08:35.226006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CParams(codec=184, codec_meta=0, clevel=1, use_dict=False, typesize=8, nthreads=1, blocksize=0, splitmode=<SplitMode.AUTO_SPLIT: 3>, filters=[160, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>], filters_meta=[0, 0, 0, 0, 0, 0], tuner=<Tuner.STUNE: 0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = blosc2.zeros((30, 30))\n",
    "array.schunk.cparams = blosc2.CParams(\n",
    "    **{\"codec\": 184, \"filters\": [filter_id], \"filters_meta\": [0], \"nthreads\": 1}\n",
    ")\n",
    "array.schunk.cparams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
