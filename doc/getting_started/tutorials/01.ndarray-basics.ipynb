{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDArray: A NDim, Compressed Data Container\n",
    "\n",
    "NDArray objects let users perform different operations with NDArray arrays like setting, copying or slicing them. In this section, we are going to see how to create and manipulate NDArray arrays. NDArray objects possess metadata and data. The data is *chunked* and *compressed*; the metadata gives information about the data itself, as well as the chunking and compression. Chunking and compression are features which make NDArray arrays very efficient for working with large data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:10.281770Z",
     "start_time": "2025-07-23T14:19:10.278507Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import blosc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an array\n",
    "Let's start by creating a 2D array with 100M elements filled with ``arange``. We can then print out the metadata, which contains information about: the array data (such as ``shape`` and ``dtype``); and how the data is compressed and stored, such as chunk- and block-shapes (``chunks`` and ``blocks``) and compression params (``CParams``). See [here](../overview.html#ndarray-an-n-dimensional-store) for an explanation of chunking and blocking.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:11.425448Z",
     "start_time": "2025-07-23T14:19:10.312282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"NDArray-info\"><tbody><tr><th style=\"text-align: left\">type</th><td style=\"text-align: left\">NDArray</td></tr><tr><th style=\"text-align: left\">shape</th><td style=\"text-align: left\">(10000, 10000)</td></tr><tr><th style=\"text-align: left\">chunks</th><td style=\"text-align: left\">(50, 10000)</td></tr><tr><th style=\"text-align: left\">blocks</th><td style=\"text-align: left\">(4, 10000)</td></tr><tr><th style=\"text-align: left\">dtype</th><td style=\"text-align: left\">int64</td></tr><tr><th style=\"text-align: left\">cratio</th><td style=\"text-align: left\">491.73</td></tr><tr><th style=\"text-align: left\">cparams</th><td style=\"text-align: left\">CParams(codec=<Codec.ZSTD: 5>, codec_meta=0, clevel=1, use_dict=False, typesize=8, nthreads=10, blocksize=320000, splitmode=<SplitMode.AUTO_SPLIT: 3>, filters=[<Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.SHUFFLE: 1>], filters_meta=[0, 0, 0, 0, 0, 0], tuner=<Tuner.STUNE: 0>)</td></tr><tr><th style=\"text-align: left\">dparams</th><td style=\"text-align: left\">DParams(nthreads=10)</td></tr></tbody></table>"
      ],
      "text/plain": [
       "type    : NDArray\n",
       "shape   : (10000, 10000)\n",
       "chunks  : (50, 10000)\n",
       "blocks  : (4, 10000)\n",
       "dtype   : int64\n",
       "cratio  : 491.73\n",
       "cparams : CParams(codec=<Codec.ZSTD: 5>, codec_meta=0, clevel=1, use_dict=False, typesize=8,\n",
       "        : nthreads=10, blocksize=320000, splitmode=<SplitMode.AUTO_SPLIT: 3>,\n",
       "        : filters=[<Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>,\n",
       "        : <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.SHUFFLE: 1>], filters_meta=[0, 0,\n",
       "        : 0, 0, 0, 0], tuner=<Tuner.STUNE: 0>)\n",
       "dparams : DParams(nthreads=10)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (10_000, 10_000)\n",
    "array = blosc2.arange(np.prod(shape), shape=shape)\n",
    "array.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``cratio`` parameter tells us how effective the compression is, since it gives the ratio between the number of bytes required to store the array in uncompressed and compressed form. Here we require almost 500x less space for the compressed array! Note that all the compression and decompression parameters are set to the default, and ``chunks`` and ``blocks`` have been selected automatically - playing around with them will affect the ``cratio`` (as well as compression and decompression speed).\n",
    "\n",
    "We can also create an NDArray by compressing a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:12.689616Z",
     "start_time": "2025-07-23T14:19:11.438406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"NDArray-info\"><tbody><tr><th style=\"text-align: left\">type</th><td style=\"text-align: left\">NDArray</td></tr><tr><th style=\"text-align: left\">shape</th><td style=\"text-align: left\">(10000, 10000)</td></tr><tr><th style=\"text-align: left\">chunks</th><td style=\"text-align: left\">(50, 10000)</td></tr><tr><th style=\"text-align: left\">blocks</th><td style=\"text-align: left\">(4, 10000)</td></tr><tr><th style=\"text-align: left\">dtype</th><td style=\"text-align: left\">float64</td></tr><tr><th style=\"text-align: left\">cratio</th><td style=\"text-align: left\">26.18</td></tr><tr><th style=\"text-align: left\">cparams</th><td style=\"text-align: left\">CParams(codec=<Codec.ZSTD: 5>, codec_meta=0, clevel=1, use_dict=False, typesize=8, nthreads=10, blocksize=320000, splitmode=<SplitMode.AUTO_SPLIT: 3>, filters=[<Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.SHUFFLE: 1>], filters_meta=[0, 0, 0, 0, 0, 0], tuner=<Tuner.STUNE: 0>)</td></tr><tr><th style=\"text-align: left\">dparams</th><td style=\"text-align: left\">DParams(nthreads=10)</td></tr></tbody></table>"
      ],
      "text/plain": [
       "type    : NDArray\n",
       "shape   : (10000, 10000)\n",
       "chunks  : (50, 10000)\n",
       "blocks  : (4, 10000)\n",
       "dtype   : float64\n",
       "cratio  : 26.18\n",
       "cparams : CParams(codec=<Codec.ZSTD: 5>, codec_meta=0, clevel=1, use_dict=False, typesize=8,\n",
       "        : nthreads=10, blocksize=320000, splitmode=<SplitMode.AUTO_SPLIT: 3>,\n",
       "        : filters=[<Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>,\n",
       "        : <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.SHUFFLE: 1>], filters_meta=[0, 0,\n",
       "        : 0, 0, 0, 0], tuner=<Tuner.STUNE: 0>)\n",
       "dparams : DParams(nthreads=10)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparray = np.linspace(0, 100, np.prod(shape), dtype=np.float64).reshape(shape)\n",
    "b2array = blosc2.asarray(nparray)\n",
    "b2array.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "or an iterator:"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:13.726763Z",
     "start_time": "2025-07-23T14:19:12.721946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"NDArray-info\"><tbody><tr><th style=\"text-align: left\">type</th><td style=\"text-align: left\">NDArray</td></tr><tr><th style=\"text-align: left\">shape</th><td style=\"text-align: left\">(1000000,)</td></tr><tr><th style=\"text-align: left\">chunks</th><td style=\"text-align: left\">(250000,)</td></tr><tr><th style=\"text-align: left\">blocks</th><td style=\"text-align: left\">(31250,)</td></tr><tr><th style=\"text-align: left\">dtype</th><td style=\"text-align: left\">[('f0', '<i4'), ('f1', '<f4'), ('f2', '<f8')]</td></tr><tr><th style=\"text-align: left\">cratio</th><td style=\"text-align: left\">2.24</td></tr><tr><th style=\"text-align: left\">cparams</th><td style=\"text-align: left\">CParams(codec=<Codec.ZSTD: 5>, codec_meta=0, clevel=1, use_dict=False, typesize=16, nthreads=10, blocksize=500000, splitmode=<SplitMode.AUTO_SPLIT: 3>, filters=[<Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.SHUFFLE: 1>], filters_meta=[0, 0, 0, 0, 0, 0], tuner=<Tuner.STUNE: 0>)</td></tr><tr><th style=\"text-align: left\">dparams</th><td style=\"text-align: left\">DParams(nthreads=10)</td></tr></tbody></table>"
      ],
      "text/plain": [
       "type    : NDArray\n",
       "shape   : (1000000,)\n",
       "chunks  : (250000,)\n",
       "blocks  : (31250,)\n",
       "dtype   : [('f0', '<i4'), ('f1', '<f4'), ('f2', '<f8')]\n",
       "cratio  : 2.24\n",
       "cparams : CParams(codec=<Codec.ZSTD: 5>, codec_meta=0, clevel=1, use_dict=False, typesize=16,\n",
       "        : nthreads=10, blocksize=500000, splitmode=<SplitMode.AUTO_SPLIT: 3>,\n",
       "        : filters=[<Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>,\n",
       "        : <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.SHUFFLE: 1>], filters_meta=[0, 0,\n",
       "        : 0, 0, 0, 0], tuner=<Tuner.STUNE: 0>)\n",
       "dparams : DParams(nthreads=10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000_000\n",
    "rng = np.random.default_rng()\n",
    "it = ((-x + 1, x - 2, rng.normal()) for x in range(N))\n",
    "sa = blosc2.fromiter(it, dtype=\"i4,f4,f8\", shape=(N,))\n",
    "sa.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Reading and modifying data\n",
    "NDArray arrays cannot be read directly, since they are compressed, and so must be decompressed first (to NumPy arrays, which are stored in memory). This can be done for the full array using the ``[:]`` operator, which returns a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:14.129497Z",
     "start_time": "2025-07-23T14:19:13.740785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = array[:]  # This will decompress the full array\n",
    "type(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "However it is often not necessary (or desirable) to load the whole array into memory. We can easily read just small parts of NDArray arrays to a NumPy array, quickly, via standard indexing routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:14.160874Z",
     "start_time": "2025-07-23T14:19:14.154634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9997, 9998, 9999], shape=(10000,))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We can modify the data in the array using standard NumPy indexing too, using either NumPy or NDArray arrays as the data source.  For example, we can set the first row to zeros and the first column to ones. ``array`` will still be a NDArray array."
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:14.478376Z",
     "start_time": "2025-07-23T14:19:14.206149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<blosc2.ndarray.NDArray object at 0x7c54c3f01550>\n"
     ]
    }
   ],
   "source": [
    "array[0, :] = blosc2.zeros(10000, dtype=array.dtype)\n",
    "array[:, 0] = np.ones(10000, dtype=array.dtype)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:14.494833Z",
     "start_time": "2025-07-23T14:19:14.489258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:14.533237Z",
     "start_time": "2025-07-23T14:19:14.526042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], shape=(10000,))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:14.704553Z",
     "start_time": "2025-07-23T14:19:14.573569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], shape=(10000,))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enlarging the array\n",
    "Existing arrays can be enlarged. This is one operation that is greatly enhanced by the chunking procedure implemented in NDArray arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:14.750151Z",
     "start_time": "2025-07-23T14:19:14.735325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10001, 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], shape=(10000,))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.resize((10_001, 10_000))\n",
    "print(array.shape)\n",
    "array[10_000, :] = 1\n",
    "array[10_000, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlarging a NumPy array requires a full copy of the data, since underlying data are stored contiguously in memory; hence new memory to hold the extended array is allocated, the old data is copied to the new memory, and then the new data is appended.\n",
    "Enlarging is a much faster operation for NDArray arrays because data is chunked, and the chunks may be stored non-contiguously in memory, so one may simply write the necessary new chunks to some arbitrary address in memory and leave the old chunks untouched.\n",
    "\n",
    "You can also shrink the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:14.791698Z",
     "start_time": "2025-07-23T14:19:14.785566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 10000)\n",
      "[       1 89990001 89990002 ... 89999997 89999998 89999999]\n"
     ]
    }
   ],
   "source": [
    "array.resize((9_000, 10_000))\n",
    "print(array.shape)\n",
    "print(array[8_999])  # This works\n",
    "# array[9_000]  # This will raise an exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistent data\n",
    "We can use the `save()` method to store the array on disk.  This is very useful when you have a large array that you want to keep around but do not need to access all the time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:15.131209Z",
     "start_time": "2025-07-23T14:19:14.827835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "-rw-r--r-- 1 lshaw lshaw 1.7M Jul 23 16:19 array_tutorial.b2nd\r\n"
     ]
    }
   ],
   "source": [
    "array.save(\"array_tutorial.b2nd\", mode=\"w\")  # , contiguous=True)\n",
    "!ls -lh array_tutorial.b2nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For arrays, it is usual to use the `.b2nd` extension. Now let's open the saved array and check it matches the original array. Let's check the data saved correctly (decompressing first to be able to compare):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:16.891739Z",
     "start_time": "2025-07-23T14:19:15.154250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2 = blosc2.open(\"array_tutorial.b2nd\")\n",
    "np.all(array2[:] == array[:])  # Make sure saved array matches original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In fact it is possible to create a NDArray array directly on disk, specifying where it will be stored, and no memory will be used at all. We may also specify the compression/decompression and other storage parameters (e.g ``chunks`` and ``blocks``). For example, a 1000x1000 array filled with the string \"pepe\" can be created like this:"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:17.099369Z",
     "start_time": "2025-07-23T14:19:16.901724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "-rw-r--r-- 1 lshaw lshaw 4.0K Jul 23 16:19 array1_tutorial.b2nd\r\n"
     ]
    }
   ],
   "source": [
    "array1 = blosc2.full(\n",
    "    (1000, 1000),\n",
    "    fill_value=b\"pepe\",\n",
    "    chunks=(100, 100),\n",
    "    blocks=(50, 50),\n",
    "    urlpath=\"array1_tutorial.b2nd\",\n",
    "    mode=\"w\",\n",
    ")\n",
    "!ls -lh array1_tutorial.b2nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We can also write direct to disk using the other constructors we saw previously."
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:18.985994Z",
     "start_time": "2025-07-23T14:19:17.129289Z"
    }
   },
   "outputs": [],
   "source": [
    "it = ((-x + 1, x - 2, rng.normal()) for x in range(N))\n",
    "sa = blosc2.fromiter(it, dtype=\"i4,f4,f8\", shape=(N,), urlpath=\"sa-1M.b2nd\", mode=\"w\")\n",
    "b2array = blosc2.asarray(nparray, urlpath=\"linspace_array.b2nd\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression params\n",
    "Let's see how to copy the data of NDArray array, but changing the compression parameters of the copy. This may be useful in many contexts, for example testing how changing the codec of an existing array affects the compression ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:19.846146Z",
     "start_time": "2025-07-23T14:19:19.004219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type    : NDArray\n",
      "shape   : (9000, 10000)\n",
      "chunks  : (500, 10000)\n",
      "blocks  : (50, 10000)\n",
      "dtype   : int64\n",
      "cratio  : 70.63\n",
      "cparams : CParams(codec=<Codec.LZ4: 1>, codec_meta=0, clevel=9, use_dict=False, typesize=8,\n",
      "        : nthreads=10, blocksize=4000000, splitmode=<SplitMode.AUTO_SPLIT: 3>,\n",
      "        : filters=[<Filter.BITSHUFFLE: 2>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>,\n",
      "        : <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>], filters_meta=[0, 0,\n",
      "        : 0, 0, 0, 0], tuner=<Tuner.STUNE: 0>)\n",
      "dparams : DParams(nthreads=10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cparams = blosc2.CParams(\n",
    "    codec=blosc2.Codec.LZ4,\n",
    "    clevel=9,\n",
    "    filters=[blosc2.Filter.BITSHUFFLE],\n",
    "    filters_meta=[0],\n",
    ")\n",
    "\n",
    "array2 = array.copy(chunks=(500, 10_000), blocks=(50, 10_000), cparams=cparams)\n",
    "print(array2.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:19:19.878533Z",
     "start_time": "2025-07-23T14:19:19.870878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type    : NDArray\n",
      "shape   : (9000, 10000)\n",
      "chunks  : (50, 10000)\n",
      "blocks  : (4, 10000)\n",
      "dtype   : int64\n",
      "cratio  : 437.77\n",
      "cparams : CParams(codec=<Codec.ZSTD: 5>, codec_meta=0, clevel=1, use_dict=False, typesize=8,\n",
      "        : nthreads=10, blocksize=320000, splitmode=<SplitMode.AUTO_SPLIT: 3>,\n",
      "        : filters=[<Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>,\n",
      "        : <Filter.NOFILTER: 0>, <Filter.NOFILTER: 0>, <Filter.SHUFFLE: 1>], filters_meta=[0, 0,\n",
      "        : 0, 0, 0, 0], tuner=<Tuner.STUNE: 0>)\n",
      "dparams : DParams(nthreads=10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(array.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In this case the compression ratio is much higher for the original array, since we have changed to a different codec that is optimised for compression speed, not compression ratio. In general there is a tradeoff between the two."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for now.  There are more examples in the [examples directory of the git repository](https://github.com/Blosc/python-blosc2/tree/main/examples/ndarray) for you to explore.  Enjoy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
